{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-rajmani2k/Generative-AI_Chatbot/blob/main/Gen_Ai_part_p3_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-YfbXwvc-5O",
        "outputId": "59dbf54a-79a1-4097-e453-42c25945c438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 500 characters of text:\n",
            "alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought alice “without pictures or conversations?” so she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getti\n",
            "Unique characters: ['\\n', ' ', '!', '(', ')', ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '’', '“', '”']\n",
            "Number of unique characters: 41\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the text file and preprocess the text\n",
        "filename = \"wonderland.txt\"\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "    raw_text = file.read()\n",
        "\n",
        "raw_text = raw_text.lower()  # Convert to lowercase to normalize text\n",
        "print(\"First 500 characters of text:\")\n",
        "print(raw_text[:500])  # Display the first 500 characters of the text\n",
        "\n",
        "# Create a sorted list of unique characters in the text\n",
        "chars = sorted(list(set(raw_text)))\n",
        "\n",
        "print(f\"Unique characters: {chars}\")\n",
        "print(f\"Number of unique characters: {len(chars)}\")\n",
        "\n",
        "\n",
        "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "\n",
        "\n",
        "# # Create mappings for characters to integers and vice versa\n",
        "# char_to_int = {char: idx for idx, char in enumerate(chars)}\n",
        "# int_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "\n",
        "# print(\"Character-to-Integer mapping example:\")\n",
        "# print({key: char_to_int[key] for key in list(char_to_int)[:10]})  # Show a sample mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoqow2xxqv2f",
        "outputId": "4163c428-5069-407e-ce34-cb790074a2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 13637\n",
            "Total unique characters: 41\n"
          ]
        }
      ],
      "source": [
        "n_char = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total characters:\", n_char)\n",
        "print(\"Total unique characters:\", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNdFQgyqeOv9",
        "outputId": "8d26d184-58bf-4f55-e34f-b1e382186d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patterns: 13537\n"
          ]
        }
      ],
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "# Loop to create input-output pairs\n",
        "for i in range(0, len(raw_text) - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]  # Sequence of 100 characters\n",
        "    seq_out = raw_text[i + seq_length]  # Next character (the target)\n",
        "    dataX.append([char_to_int[char] for char in seq_in])  # Convert input characters to integers\n",
        "    dataY.append(char_to_int[seq_out])  # Convert output character to integer\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total patterns:\", n_patterns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhkB0NeUiA56",
        "outputId": "b34695b9-c995-4c47-c181-8bd97393aa31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13537"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(dataX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXJ2BQlUia_b",
        "outputId": "1c7685e4-f736-4ef2-db2f-aac9fc17b562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13537"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3PHapR852Bv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfacptImgRTZ",
        "outputId": "2f09d3d4-0249-4997-fffe-19cf98a2c89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape (X): (13537, 100, 1)\n",
            "Output shape (y): (13537, 41)\n"
          ]
        }
      ],
      "source": [
        "# Reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length,1))\n",
        "X = X / float(n_vocab)\n",
        "# One-hot encode the output variable\n",
        "y = to_categorical(dataY, num_classes=len(chars))  # Specify the number of classes explicitly\n",
        "\n",
        "print(\"Input shape (X):\", X.shape)  # Expected: (n_patterns, seq_length, 1)\n",
        "print(\"Output shape (y):\", y.shape)  # Expected: (n_patterns, n_vocab)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "qwqRUu6r6gMo",
        "outputId": "40ec1f6c-d11d-478e-9dbb-23d040c857b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m264,192\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)                  │          \u001b[38;5;34m10,537\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">264,192</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,537</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m274,729\u001b[0m (1.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,729</span> (1.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m274,729\u001b[0m (1.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,729</span> (1.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2])))  # Corrected input shape\n",
        "model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))  # Output layer with softmax activation\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRg0M4dI-cv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGUkt20_h3Kn",
        "outputId": "219f89a7-ec49-4da8-b03a-f3052358eb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1429\n",
            "Epoch 1: loss improved from inf to 3.01912, saving model to weights-improvement-01-3.0191.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 3.1418\n",
            "Epoch 2/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9581\n",
            "Epoch 2: loss improved from 3.01912 to 2.95788, saving model to weights-improvement-02-2.9579.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9581\n",
            "Epoch 3/50\n",
            "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9565\n",
            "Epoch 3: loss improved from 2.95788 to 2.95145, saving model to weights-improvement-03-2.9515.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9563\n",
            "Epoch 4/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9481\n",
            "Epoch 4: loss improved from 2.95145 to 2.94504, saving model to weights-improvement-04-2.9450.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9480\n",
            "Epoch 5/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9423\n",
            "Epoch 5: loss improved from 2.94504 to 2.92999, saving model to weights-improvement-05-2.9300.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.9421\n",
            "Epoch 6/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9221\n",
            "Epoch 6: loss improved from 2.92999 to 2.90345, saving model to weights-improvement-06-2.9034.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.9219\n",
            "Epoch 7/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8662\n",
            "Epoch 7: loss improved from 2.90345 to 2.85963, saving model to weights-improvement-07-2.8596.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 2.8661\n",
            "Epoch 8/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8402\n",
            "Epoch 8: loss improved from 2.85963 to 2.82711, saving model to weights-improvement-08-2.8271.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.8401\n",
            "Epoch 9/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.7918\n",
            "Epoch 9: loss improved from 2.82711 to 2.79243, saving model to weights-improvement-09-2.7924.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 2.7918\n",
            "Epoch 10/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7702\n",
            "Epoch 10: loss improved from 2.79243 to 2.76502, saving model to weights-improvement-10-2.7650.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.7701\n",
            "Epoch 11/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7624\n",
            "Epoch 11: loss improved from 2.76502 to 2.74217, saving model to weights-improvement-11-2.7422.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 2.7622\n",
            "Epoch 12/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7218\n",
            "Epoch 12: loss improved from 2.74217 to 2.72301, saving model to weights-improvement-12-2.7230.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7218\n",
            "Epoch 13/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6952\n",
            "Epoch 13: loss improved from 2.72301 to 2.70443, saving model to weights-improvement-13-2.7044.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.6953\n",
            "Epoch 14/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7127\n",
            "Epoch 14: loss improved from 2.70443 to 2.68936, saving model to weights-improvement-14-2.6894.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 2.7122\n",
            "Epoch 15/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6888\n",
            "Epoch 15: loss improved from 2.68936 to 2.67467, saving model to weights-improvement-15-2.6747.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.6885\n",
            "Epoch 16/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6601\n",
            "Epoch 16: loss improved from 2.67467 to 2.65927, saving model to weights-improvement-16-2.6593.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6601\n",
            "Epoch 17/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6348\n",
            "Epoch 17: loss improved from 2.65927 to 2.64924, saving model to weights-improvement-17-2.6492.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.6351\n",
            "Epoch 18/50\n",
            "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6163\n",
            "Epoch 18: loss improved from 2.64924 to 2.63280, saving model to weights-improvement-18-2.6328.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6170\n",
            "Epoch 19/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6104\n",
            "Epoch 19: loss improved from 2.63280 to 2.61655, saving model to weights-improvement-19-2.6165.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.6105\n",
            "Epoch 20/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6160\n",
            "Epoch 20: loss improved from 2.61655 to 2.60438, saving model to weights-improvement-20-2.6044.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.6158\n",
            "Epoch 21/50\n",
            "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.5830\n",
            "Epoch 21: loss improved from 2.60438 to 2.58748, saving model to weights-improvement-21-2.5875.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.5832\n",
            "Epoch 22/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5665\n",
            "Epoch 22: loss improved from 2.58748 to 2.56825, saving model to weights-improvement-22-2.5682.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.5665\n",
            "Epoch 23/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5615\n",
            "Epoch 23: loss improved from 2.56825 to 2.55211, saving model to weights-improvement-23-2.5521.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5613\n",
            "Epoch 24/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5369\n",
            "Epoch 24: loss improved from 2.55211 to 2.53310, saving model to weights-improvement-24-2.5331.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.5368\n",
            "Epoch 25/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5041\n",
            "Epoch 25: loss improved from 2.53310 to 2.51497, saving model to weights-improvement-25-2.5150.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5043\n",
            "Epoch 26/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4729\n",
            "Epoch 26: loss improved from 2.51497 to 2.48975, saving model to weights-improvement-26-2.4898.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.4733\n",
            "Epoch 27/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4570\n",
            "Epoch 27: loss improved from 2.48975 to 2.45689, saving model to weights-improvement-27-2.4569.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.4570\n",
            "Epoch 28/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4030\n",
            "Epoch 28: loss improved from 2.45689 to 2.42642, saving model to weights-improvement-28-2.4264.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.4035\n",
            "Epoch 29/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3799\n",
            "Epoch 29: loss improved from 2.42642 to 2.38570, saving model to weights-improvement-29-2.3857.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.3800\n",
            "Epoch 30/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3493\n",
            "Epoch 30: loss improved from 2.38570 to 2.35561, saving model to weights-improvement-30-2.3556.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.3494\n",
            "Epoch 31/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3132\n",
            "Epoch 31: loss improved from 2.35561 to 2.30023, saving model to weights-improvement-31-2.3002.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.3130\n",
            "Epoch 32/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2480\n",
            "Epoch 32: loss improved from 2.30023 to 2.25844, saving model to weights-improvement-32-2.2584.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.2482\n",
            "Epoch 33/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.1982\n",
            "Epoch 33: loss improved from 2.25844 to 2.20709, saving model to weights-improvement-33-2.2071.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 2.1983\n",
            "Epoch 34/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1402\n",
            "Epoch 34: loss improved from 2.20709 to 2.15845, saving model to weights-improvement-34-2.1584.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.1405\n",
            "Epoch 35/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1121\n",
            "Epoch 35: loss improved from 2.15845 to 2.10774, saving model to weights-improvement-35-2.1077.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1121\n",
            "Epoch 36/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0508\n",
            "Epoch 36: loss improved from 2.10774 to 2.04791, saving model to weights-improvement-36-2.0479.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.0508\n",
            "Epoch 37/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9913\n",
            "Epoch 37: loss improved from 2.04791 to 1.99047, saving model to weights-improvement-37-1.9905.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.9913\n",
            "Epoch 38/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9054\n",
            "Epoch 38: loss improved from 1.99047 to 1.93579, saving model to weights-improvement-38-1.9358.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.9059\n",
            "Epoch 39/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8537\n",
            "Epoch 39: loss improved from 1.93579 to 1.87940, saving model to weights-improvement-39-1.8794.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.8545\n",
            "Epoch 40/50\n",
            "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8188\n",
            "Epoch 40: loss improved from 1.87940 to 1.82253, saving model to weights-improvement-40-1.8225.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 1.8189\n",
            "Epoch 41/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7652\n",
            "Epoch 41: loss improved from 1.82253 to 1.76389, saving model to weights-improvement-41-1.7639.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.7652\n",
            "Epoch 42/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6704\n",
            "Epoch 42: loss improved from 1.76389 to 1.69871, saving model to weights-improvement-42-1.6987.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.6709\n",
            "Epoch 43/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6148\n",
            "Epoch 43: loss improved from 1.69871 to 1.65623, saving model to weights-improvement-43-1.6562.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6155\n",
            "Epoch 44/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5631\n",
            "Epoch 44: loss improved from 1.65623 to 1.59737, saving model to weights-improvement-44-1.5974.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.5638\n",
            "Epoch 45/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5114\n",
            "Epoch 45: loss improved from 1.59737 to 1.53258, saving model to weights-improvement-45-1.5326.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5117\n",
            "Epoch 46/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4335\n",
            "Epoch 46: loss improved from 1.53258 to 1.47337, saving model to weights-improvement-46-1.4734.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 1.4346\n",
            "Epoch 47/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4048\n",
            "Epoch 47: loss improved from 1.47337 to 1.43542, saving model to weights-improvement-47-1.4354.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.4054\n",
            "Epoch 48/50\n",
            "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3556\n",
            "Epoch 48: loss improved from 1.43542 to 1.38345, saving model to weights-improvement-48-1.3834.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.3564\n",
            "Epoch 49/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3172\n",
            "Epoch 49: loss improved from 1.38345 to 1.33257, saving model to weights-improvement-49-1.3326.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3175\n",
            "Epoch 50/50\n",
            "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2482\n",
            "Epoch 50: loss improved from 1.33257 to 1.27081, saving model to weights-improvement-50-1.2708.keras\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.2486\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x791f21b09fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the file path for saving the model weights, ensuring it ends with '.keras'\n",
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.keras\" # Changed '.hdf5' to '.keras'\n",
        "\n",
        "# Create a ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True)\n",
        "\n",
        "# List of callbacks\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmcYAhEGoubV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZG9iOERh5Pr"
      },
      "outputs": [],
      "source": [
        "# # # Fit the model\n",
        "# model.fit(X, y, epochs=4, batch_size=128, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kz296nIPh5MU"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/weights-improvement-50-1.2708.keras\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xcw-AuTDpSH_"
      },
      "outputs": [],
      "source": [
        "model.load_weights(filename)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QP4Nfchbpgq-"
      },
      "outputs": [],
      "source": [
        "# With this line:\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q3YCJpoexpUu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNAYqFG1qcGU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate a random starting index\n",
        "start = np.random.randint(0, len(dataX))  # Random index\n",
        "pattern = dataX[start]\n",
        "\n",
        "# Print the seed\n",
        "print(\"Seed:\")\n",
        "print(\"'{}'\".format(''.join([int_to_char[value] for value in pattern])))\n",
        "\n",
        "# Generate characters\n",
        "for i in range(1000):\n",
        "    # Reshape the input pattern for the model\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    # Normalize the values\n",
        "    x = x / float(n_vocab)\n",
        "    # Additional processing can be added here\n",
        "    prediction = model.predict(x,verbose=0)\n",
        "    index = numpy. argmax (prediction)\n",
        "    result = int_to_char [index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys. stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import numpy as np\n",
        "# # Generate a random starting index\n",
        "# start = np.random.randint(0, len(dataX))  # Random index\n",
        "# pattern = dataX[start]\n",
        "# # Print the seed\n",
        "# print(\"Seed:\")\n",
        "# print(\"'{}'\".format(''.join([int_to_char[value] for value in pattern])))\n",
        "# # Generate characters\n",
        "# for i in range(1000):\n",
        "#     # Reshape the input pattern for the model\n",
        "#     x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "#     # Normalize the values\n",
        "#     x = x / float(n_vocab)\n",
        "#     # Additional processing can be added here\n",
        "#     prediction = model.predict(x,verbose=0)\n",
        "#     index = numpy. argmax (prediction)\n",
        "#     result = int_to_char [index]\n",
        "#     seq_in = [int_to_char[value] for value in pattern]\n",
        "#     sys. stdout.write(result)\n",
        "#     pattern.append(index)\n",
        "#     pattern = pattern[1:len(pattern)]\n",
        "#  check thi socede why it is not abley o generate further based on seed\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import sys\n",
        "\n",
        "# ... (Your existing code for data loading, preprocessing, and model training)\n",
        "\n",
        "# ... (Your model loading code)\n",
        "\n",
        "# With this line: (Corrected int_to_char creation)\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# Generate a random starting index\n",
        "start = np.random.randint(0, len(dataX))  # Random index\n",
        "pattern = list(dataX[start]) # Convert to list for mutability\n",
        "\n",
        "\n",
        "# Print the seed\n",
        "print(\"Seed:\")\n",
        "print(\"'{}'\".format(''.join([int_to_char[value] for value in pattern])))\n",
        "\n",
        "# Generate characters\n",
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction) # Use numpy.argmax\n",
        "    result = int_to_char[index]\n",
        "    sys.stdout.write(result) # Correct stdout\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)] #Correct slicing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jrw_uAC9Bo2",
        "outputId": "3d569abc-f592-4ee8-ef66-81bf508d5645"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "' herself, as she wandered about in the wood, “is to grow to my right size again; and the second thin'\n",
            "g if tome  int hemt de the hase aade ger hene mean her  and feongdg atite aates,as she want herting oo hem  and toink da anvel  and ooonedd tot anr thrt ditn lo anl she wist de the mimt  and she qert dodng puupes on the same, and she qeet quite ao oo eem coosd all ser want wo to she woate  t he the querl sfther bo soee as the diol, aad  alite celi the ras ceard iou ii ger her, and then her lo tee hooee aader, af  am chollos tasy hac no aogoee an har fand “has she rast oo the iing  and ae rery doonn oos rooe oa die eiteh aarrne the seete rab eep tee tootee and she rert wonn io to vos mame mo tar mooe aa in eer hooeng an io,reit  aat in thi kerr oo thi kent  nn t in the that had aever and the sere whr seat no tare oo ne rhy leke  and ae nar quite aerere teet hn  an th  ou the could aov ree hid athsnne to tes see wabbit  aut whe  an cellte the kaad “undd  to the sooen sard thet nn hane  no t sset  sit’ it to ter mokk aa ang ,uoon then  wiwd ao  ehore that s s shedlit  iit, aet  than so ha"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0NH50xz_yqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import sys\n",
        "#other way implementing it using variation in temperarie\n",
        "\n",
        "# # Sampling function with temperature scaling\n",
        "# def sample_with_temperature(predictions, temperature=1.0):\n",
        "#     predictions = np.asarray(predictions).astype(\"float64\")\n",
        "#     predictions = np.log(predictions + 1e-8) / temperature\n",
        "#     exp_predictions = np.exp(predictions)\n",
        "#     predictions = exp_predictions / np.sum(exp_predictions)\n",
        "#     return np.random.choice(len(predictions), p=predictions)\n",
        "\n",
        "# # Generate a random starting index\n",
        "# start = np.random.randint(0, len(dataX))\n",
        "# pattern = dataX[start]\n",
        "\n",
        "# # Print the seed\n",
        "# seed_text = ''.join([int_to_char[value] for value in pattern])\n",
        "# print(\"Seed Text:\")\n",
        "# print(f\"'{seed_text}'\")\n",
        "\n",
        "# # Generate characters\n",
        "# print(\"\\nGenerated Text:\")\n",
        "# generated_text = \"\"\n",
        "# for i in range(1000):  # Generate 1000 characters\n",
        "#     x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "#     x = x / float(n_vocab)\n",
        "\n",
        "#     # Predict the next character\n",
        "#     prediction = model.predict(x, verbose=0)\n",
        "#     index = sample_with_temperature(prediction[0], temperature=0.7)  # Moderate temperature for balance\n",
        "#     result = int_to_char[index]\n",
        "#     generated_text += result\n",
        "#     sys.stdout.write(result)\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # Update the pattern\n",
        "#     pattern.append(index)\n",
        "#     pattern = pattern[1:]\n",
        "\n",
        "# print(\"\\n\\nPrediction complete.\")\n"
      ],
      "metadata": {
        "id": "vMdADTdQ9r8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attentive Chatbot"
      ],
      "metadata": {
        "id": "9AiQF7vsFx7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ySTjk9hFExl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMzUsAvMUwKpv3M5l5ZoX6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}